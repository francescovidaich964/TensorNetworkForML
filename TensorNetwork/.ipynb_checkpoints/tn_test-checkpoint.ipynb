{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tnrange\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,\"../\")\n",
    "import data_generator as gen\n",
    "import TensorNetwork as tn\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset, SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumpyDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Add description\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data, label):\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return (self.data[index], self.label[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(data, label, train_perc, val_perc, train_batch_size, val_batch_size, test_batch_size):\n",
    "    \"\"\"\n",
    "    Add description\n",
    "    \"\"\"\n",
    "    \n",
    "    def psi(x):\n",
    "        x = np.array((np.sin(np.pi*x/2),np.cos(np.pi*x/2)))\n",
    "        return np.transpose(x, [1,2,0])\n",
    "\n",
    "\n",
    "    # flatten images\n",
    "    x = data.reshape(len(data),-1)\n",
    "    # embedd them\n",
    "    x = psi(x)\n",
    "    \n",
    "    # training/test splitting\n",
    "    m = int(len(x)*train_perc)\n",
    "    x_train= x[:m]\n",
    "    y_train = label[:m]\n",
    "    x_test =  x[m:]\n",
    "    y_test = label[m:]\n",
    "    \n",
    "    # define custom NumpyDatasets\n",
    "    train_set = NumpyDataset(x_train, y_train)\n",
    "    test_set =  NumpyDataset(x_test, y_test)\n",
    "   \n",
    "    train_len = int(m*(1-val_perc))\n",
    "    train_sampler = SubsetRandomSampler(np.arange(train_len))\n",
    "    val_sampler = SubsetRandomSampler(np.arange(train_len,m))\n",
    "\n",
    "    train_loader = DataLoader(train_set, train_batch_size, sampler=train_sampler, drop_last=True, collate_fn=lambda x: x)\n",
    "    val_loader = DataLoader(train_set, val_batch_size, sampler=val_sampler, drop_last=True, collate_fn=lambda x: x)\n",
    "    test_loader = DataLoader(test_set, test_batch_size, drop_last=False, collate_fn=lambda x: x)\n",
    "\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 5000\n",
    "linear_dim = 14\n",
    "M = 20\n",
    "B = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "(data, label) = gen.create_dataset(n_samples, linear_dim=linear_dim, sigma=0.2)\n",
    "batch_size = {'train_batch_size':B, 'val_batch_size':128, 'test_batch_size':128}\n",
    "train_loader, val_loader, test_loader = prepare_dataset(data, label, 0.8, 0.2, **batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'TensorNetwork' from '/home/francesco/UNIPD/Information_Theory/TensorNetworkForML/TensorNetwork/TensorNetwork.py'>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(tn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_batch = next(iter(train_loader))\n",
    "x_calibration = np.array([calibration_batch[i][0] for i in range(len(calibration_batch))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing weights...\n",
      "Scaling factor: 12.80\n",
      "Calibrating weights on dataset...\n",
      "f_max for random input of 32 samples :  3.2768296311353677e-11\n",
      "Rescaling factor for calibration:  0.8841122695344825\n",
      "f_max for random input of 32 samples (after):  1.0000000000000004\n"
     ]
    }
   ],
   "source": [
    "N = linear_dim**2\n",
    "net = tn.Network(N=N, M=M, L=2, normalize=True, calibration_X=x_calibration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00790753 0.3074999  0.16890961 0.16277957 0.04811798 0.16239332\n",
      "  0.08155109 0.10448381 0.11217815 0.07095648 0.09965655 0.336287\n",
      "  0.10240513 0.10299295 0.14679404 0.14415213 0.11631908 0.24325033\n",
      "  0.0261345  0.03703894 0.30063958 0.18302107 0.02222488 0.3758994\n",
      "  0.11057214 0.02498488 0.12019461 0.20047174 0.04602691 0.06340908\n",
      "  0.06072076 1.        ]\n",
      " [0.00683578 0.26589838 0.14541161 0.14028439 0.04163729 0.13966663\n",
      "  0.0700716  0.09009966 0.09649544 0.06104302 0.08613254 0.28867842\n",
      "  0.08799728 0.08846514 0.12691663 0.12422855 0.10029263 0.20994665\n",
      "  0.02245252 0.03177381 0.25855269 0.15782992 0.01920933 0.32452484\n",
      "  0.09525712 0.02155371 0.10348284 0.1724431  0.03958961 0.05464891\n",
      "  0.05234126 0.86317481]]\n"
     ]
    }
   ],
   "source": [
    "f = net.forward(x_calibration)\n",
    "print(f.elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1eab22d44934bd5a4309e23856549f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch loop', max=10, style=ProgressStyle(description_width='iâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Tensor description ==========\n",
      "Tensor shape:  (2, 32)\n",
      "Tensor rank:  2\n",
      "Axes names:  ['l' 'b']\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'elem'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-b7e63445f58e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/UNIPD/Information_Theory/TensorNetworkForML/TensorNetwork/TensorNetwork.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_loader, val_loader, lr, n_epochs, early_stopping, print_freq)\u001b[0m\n\u001b[1;32m    701\u001b[0m                 \u001b[0;31m# Select r/l sweep depending on l_pos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml_pos\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m                     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mr_sweep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml_pos\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m                     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml_sweep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/UNIPD/Information_Theory/TensorNetworkForML/TensorNetwork/TensorNetwork.py\u001b[0m in \u001b[0;36mr_sweep\u001b[0;34m(self, X, y, f, lr)\u001b[0m\n\u001b[1;32m    848\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m             \u001b[0;31m#print(\"\\nright sweep step \",i)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 850\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mr_sweep_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/UNIPD/Information_Theory/TensorNetworkForML/TensorNetwork/TensorNetwork.py\u001b[0m in \u001b[0;36mr_sweep_step\u001b[0;34m(self, f, y, lr, batch_size)\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m         \u001b[0;31m######################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    966\u001b[0m         \u001b[0my_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m         \u001b[0;31m#print(\"Target: \", y_target)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'elem'"
     ]
    }
   ],
   "source": [
    "train_acc, val_acc = net.train(train_loader, val_loader, lr = 0.01, n_epochs = 10, print_freq=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(iter(train_loader))\n",
    "x = np.array([data[i][0] for i in range(len(data))])\n",
    "y = np.array([data[i][1] for i in range(len(data))])\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 0, 1, 0, 1, 0, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = net.forward(x)\n",
    "print(f.elem.shape)\n",
    "y_pred = np.argmax(f.elem, axis=0)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.accuracy(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling in the number of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = [1000*i**2 for i in range(1,9)]\n",
    "print(\"Number of samples tried: \\n\", n_samples)\n",
    "\n",
    "# keep them fixed\n",
    "linear_dim = 5\n",
    "M = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "times_n_samples = []\n",
    "for n in n_samples:\n",
    "    print(\"Testing with %d samples...\"%n)\n",
    "    (data, label) = gen.create_dataset(n, sigma=0.7)\n",
    "    batch_size = {'train_batch_size':16, 'val_batch_size':128, 'test_batch_size':128}\n",
    "    train_loader, val_loader, test_loader = prepare_dataset(data, label, 0.8, 0.2, **batch_size)\n",
    "    \n",
    "    # independent from the number of samples\n",
    "    net = tn.Network(N=linear_dim**2, M=M, L=2)\n",
    "    \n",
    "    start = time.time()\n",
    "    train_acc, val_acc = net.train(train_loader, val_loader, lr = 0.5, n_epochs = 1, print_freq=1)\n",
    "    dt = time.time() - start\n",
    "    print(\"Time for 1 epoch: %.2f s \\n\"%dt)\n",
    "    times_n_samples.append(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(n_samples, times_n_samples, '-o', label='M = %d \\nlinear dim = %d'%(M,linear_dim))\n",
    "plt.xlabel(\"Number of samples\", fontsize=16)\n",
    "plt.ylabel(\"Time for one epoch [s]\", fontsize=16)\n",
    "plt.title(r\"Training time vs $n_{samples}$\", fontsize=16)\n",
    "plt.legend(fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling in the number of pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_dims = np.arange(4,29,4)\n",
    "print(\"Linear dimensions tested: \\n\", linear_dims)\n",
    "\n",
    "# keep them fixed\n",
    "n_samples = 1000\n",
    "M = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "times_linear_dims = []\n",
    "for linear_dim in linear_dims:\n",
    "    print(\"Testing with %d x %d images...\"%(linear_dim,linear_dim))\n",
    "    (data, label) = gen.create_dataset(n_samples, sigma=0.7, linear_dim = linear_dim)\n",
    "    batch_size = {'train_batch_size':16, 'val_batch_size':128, 'test_batch_size':128}\n",
    "    train_loader, val_loader, test_loader = prepare_dataset(data, label, 0.8, 0.2, **batch_size)\n",
    "    \n",
    "    # independent from the number of samples\n",
    "    net = tn.Network(N=linear_dim**2, M=M, L=2)\n",
    "    \n",
    "    start = time.time()\n",
    "    train_acc, val_acc = net.train(train_loader, val_loader, lr = 0.5, n_epochs = 1, print_freq=1)\n",
    "    dt = time.time() - start\n",
    "    print(\"Time for 1 epoch: %.2f s \\n\"%dt)\n",
    "    times_linear_dims.append(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(linear_dims**2, times_linear_dims, '-o', label='M = %d \\nnum samples = %d'%(M,n_samples))\n",
    "plt.xlabel(\"Number of pixels\", fontsize=16)\n",
    "plt.ylabel(\"Time for one epoch [s]\", fontsize=16)\n",
    "plt.title(r\"Training time vs $n_{pixels}$\", fontsize=16)\n",
    "plt.legend(fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling in the bond dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ms = [10*i for i in range(1,11)]\n",
    "print(\"Bond dimensions tested: \\n\", Ms)\n",
    "\n",
    "# keep them fixed\n",
    "n_samples = 1000\n",
    "linear_dim = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "times_bond_dims = []\n",
    "for M in Ms:\n",
    "    print(\"Testing with bond dimension %d...\"%M)\n",
    "    (data, label) = gen.create_dataset(n_samples, sigma=0.7)\n",
    "    batch_size = {'train_batch_size':16, 'val_batch_size':128, 'test_batch_size':128}\n",
    "    train_loader, val_loader, test_loader = prepare_dataset(data, label, 0.8, 0.2, **batch_size)\n",
    "    \n",
    "    # independent from the number of samples\n",
    "    net = tn.Network(N=linear_dim**2, M=M, L=2)\n",
    "    \n",
    "    start = time.time()\n",
    "    train_acc, val_acc = net.train(train_loader, val_loader, lr = 0.5, n_epochs = 1, print_freq=1)\n",
    "    dt = time.time() - start\n",
    "    print(\"Time for 1 epoch: %.2f s \\n\"%dt)\n",
    "    times_bond_dims.append(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(Ms, times_bond_dims, '-o', label='linear dim = %d \\nnum samples = %d'%(linear_dim,n_samples))\n",
    "plt.xlabel(\"Bond dimension\", fontsize=16)\n",
    "plt.ylabel(\"Time for one epoch [s]\", fontsize=16)\n",
    "plt.title(\"Training time vs bond dimension\", fontsize=16)\n",
    "plt.legend(fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight initialization\n",
    "\n",
    "**Objective:** study what is the dependence in the output magnitude of the various dimensions so that we can choose how to normalize the matrices A during initialization.\n",
    "\n",
    "**Parameters:**\n",
    "* Number of pixels N\n",
    "* Bond dimension M\n",
    "* Batch size B\n",
    "* Embedding dimension D (fixed to 2)\n",
    "\n",
    "Only the first 3 will be inquired.\n",
    "\n",
    "**Methodology:** Use random input in [0,1] and random initialization in [0,1] for different dimensions and look at the absolute value of the output (take the output among the L with the highest absolute value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "reload(tn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependence on the number of pixels N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_dims = np.arange(4,16)\n",
    "print(\"Linear dimensions tested: \\n\", linear_dims)\n",
    "\n",
    "# keep them fixed\n",
    "n_samples = 1000\n",
    "M = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "magnitude_linear_dims = []\n",
    "for linear_dim in linear_dims:\n",
    "    print(\"Testing with %d x %d images...\"%(linear_dim,linear_dim))\n",
    "    (data, label) = gen.create_dataset(n_samples, sigma=0.7, linear_dim = linear_dim)\n",
    "    batch_size = {'train_batch_size':16, 'val_batch_size':128, 'test_batch_size':128}\n",
    "    train_loader, val_loader, test_loader = prepare_dataset(data, label, 0.8, 0.2, **batch_size)\n",
    "    \n",
    "    # independent from the number of samples\n",
    "    net = tn.Network(N=linear_dim**2, M=M, L=2)\n",
    "    \n",
    "    batch = next(iter(train_loader))\n",
    "    X = np.array([batch[i][0] for i in range(len(batch))])\n",
    "    f = net.forward(X)\n",
    "    f_max = np.abs(f.elem).max()\n",
    "    magnitude_linear_dims.append(f_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "magnitude_linear_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ns = linear_dims**2\n",
    "y = np.log10(magnitude_linear_dims)\n",
    "X = Ns.reshape(-1,1)\n",
    "reg = LinearRegression().fit(X, y)\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(Ns, y, label = 'data')\n",
    "plt.plot(Ns, reg.predict(X), label = 'slope = %.2f'%reg.coef_)\n",
    "plt.ylabel(r'$log_{10}(f_{max})$', fontsize = 16)\n",
    "plt.xlabel('Number of pixels N', fontsize = 16)\n",
    "plt.legend(fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the dependence on N is exponential, meaning that we can have an exponential suppression (or divergence) if the network is not accurately initialized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Isolating dependence C(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scaled = y - Ns*np.log10(M)\n",
    "X = Ns.reshape(-1,1)\n",
    "reg_C = LinearRegression().fit(X, y_scaled)\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(Ns, y_scaled, label = 'data')\n",
    "plt.plot(Ns, reg_C.predict(X), label = 'slope = %.2f'%reg_C.coef_)\n",
    "plt.ylabel(r'$log_{10}(f_{max})$', fontsize = 16)\n",
    "plt.xlabel('Number of pixels N', fontsize = 16)\n",
    "plt.legend(fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1/(10**(-0.18))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bond dimension M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ms = [5*i for i in range(1,21)]\n",
    "print(\"Bond dimensions tested: \\n\", Ms)\n",
    "\n",
    "# keep them fixed\n",
    "n_samples = 1000\n",
    "linear_dim = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "magnitude_bond_dims = []\n",
    "for M in Ms:\n",
    "    print(\"Testing with bond dimension %d...\"%M)\n",
    "    (data, label) = gen.create_dataset(n_samples, sigma=0.7, linear_dim=linear_dim)\n",
    "    batch_size = {'train_batch_size':16, 'val_batch_size':128, 'test_batch_size':128}\n",
    "    train_loader, val_loader, test_loader = prepare_dataset(data, label, 0.8, 0.2, **batch_size)\n",
    "    \n",
    "    # independent from the number of samples\n",
    "    net = tn.Network(N=linear_dim**2, M=M, L=2)\n",
    "    \n",
    "    batch = next(iter(train_loader))\n",
    "    X = np.array([batch[i][0] for i in range(len(batch))])\n",
    "    f = net.forward(X)\n",
    "    f_max = np.abs(f.elem).max()\n",
    "    magnitude_bond_dims.append(f_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.log10(magnitude_bond_dims)\n",
    "X = np.log10(np.array(Ms)).reshape(-1,1)\n",
    "reg_M = LinearRegression().fit(X, y)\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(X, y, label = 'data')\n",
    "plt.plot(X, reg_M.predict(X), label = 'slope = %.3f'%reg_M.coef_)\n",
    "plt.ylabel(r'$log_{10}(f_{max})$', fontsize = 16)\n",
    "plt.xlabel(r'Bond dimension $log_{10}(M)$', fontsize = 16)\n",
    "plt.legend(fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(10**reg_M.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output magnitude has a power law dependence on the bond dimension. Notice how the slope is equal to N.\n",
    "This makes sense since we already know that f is exponential in N. Now we also can approximate the scaling of the f as:\n",
    "$$f \\approx C(N)*M^N$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch dimension B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 20\n",
    "n_samples = 1000\n",
    "linear_dim = 5\n",
    "\n",
    "train_batch_sizes = np.array([2**i for i in range(1,10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "magnitude_batch_size = []\n",
    "for B in train_batch_sizes:\n",
    "    (data, label) = gen.create_dataset(n_samples, sigma=0.7, linear_dim = linear_dim)\n",
    "    batch_size = {'train_batch_size': int(B), 'val_batch_size':128, 'test_batch_size':128}\n",
    "    train_loader, val_loader, test_loader = prepare_dataset(data, label, 0.8, 0.2, **batch_size)\n",
    "    \n",
    "    # independent from the number of samples\n",
    "    net = tn.Network(N=linear_dim**2, M=M, L=2)\n",
    "    \n",
    "    batch = next(iter(train_loader))\n",
    "    X = np.array([batch[i][0] for i in range(len(batch))])\n",
    "    f = net.forward(X)\n",
    "    f_max = np.abs(f.elem).max()\n",
    "    magnitude_batch_size.append(f_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(train_batch_sizes, magnitude_batch_size, label = 'data')\n",
    "plt.ylabel(r'$f_{max}$', fontsize = 16)\n",
    "plt.xlabel('Batch size B', fontsize = 16)\n",
    "plt.legend(fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No clear dependence emerges on the batch size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion on initialization\n",
    "\n",
    "The simplest and most reliable initialization is the one that takes into account the number of pixels given as input and disregards all the rest. However remains the problem of choosing the factor with which the weights should be divided. To find an exact factor a priori is not immediate and is also a risky procedure, hence it's better to devise an empirical method to do so.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_dim = 5\n",
    "n_samples = 1000\n",
    "M = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(tn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Cs = np.arange(1,21)\n",
    "(data, label) = gen.create_dataset(n_samples, sigma=0.7, linear_dim = linear_dim)\n",
    "batch_size = {'train_batch_size':16, 'val_batch_size':128, 'test_batch_size':128}\n",
    "train_loader, val_loader, test_loader = prepare_dataset(data, label, 0.8, 0.2, **batch_size)\n",
    "batch = next(iter(train_loader))\n",
    "X = np.array([batch[i][0] for i in range(len(batch))])\n",
    "\n",
    "magnitude_C = []\n",
    "for C in Cs:\n",
    "    \n",
    "    net = tn.Network(N=linear_dim**2, M=M, L=2, normalize=False)\n",
    "    \n",
    "    for i in range(net.N):\n",
    "        net.As[i].elem *= C\n",
    "    \n",
    "    f = net.forward(X)\n",
    "    f_max = np.abs(f.elem).max()\n",
    "    print('f_max: ', f_max)\n",
    "    magnitude_C.append(f_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "X = np.log10(Cs).reshape(-1,1)\n",
    "y = np.log10(np.array(magnitude_C))\n",
    "y = y/y[0]\n",
    "reg_scale = LinearRegression().fit(X, y)\n",
    "plt.plot(X, y, label='data')\n",
    "plt.plot(X, reg_scale.predict(X), label = 'slope = %.2f\\nintercept = %.2f'%(reg_scale.coef_,reg_scale.intercept_))\n",
    "plt.ylabel(r'$log_{10}(f_{max})$', fontsize = 16)\n",
    "plt.xlabel(r'Scaling factor $log_{10}(C)$', fontsize = 16)\n",
    "plt.legend(fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ms = np.array([5*i for i in range(1,21)])\n",
    "Cs = np.arange(1,21)\n",
    "(data, label) = gen.create_dataset(n_samples, sigma=0.7, linear_dim = linear_dim)\n",
    "batch_size = {'train_batch_size':16, 'val_batch_size':128, 'test_batch_size':128}\n",
    "train_loader, val_loader, test_loader = prepare_dataset(data, label, 0.8, 0.2, **batch_size)\n",
    "batch = next(iter(train_loader))\n",
    "X = np.array([batch[i][0] for i in range(len(batch))])\n",
    "\n",
    "magnitude_C_M = []\n",
    "for M in Ms:\n",
    "    magnitude_C = []\n",
    "    for C in Cs:\n",
    "\n",
    "        net = tn.Network(N=linear_dim**2, M=M, L=2, normalize=False)\n",
    "\n",
    "        for i in range(net.N):\n",
    "            net.As[i].elem *= C\n",
    "\n",
    "        f = net.forward(X)\n",
    "        f_max = np.abs(f.elem).max()\n",
    "        magnitude_C.append(f_max)\n",
    "        \n",
    "    magnitude_C = np.array(magnitude_C)\n",
    "    magnitude_C_M.append(magnitude_C)\n",
    "    \n",
    "magnitude_C_M = np.array(magnitude_C_M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "magnitude_C_M.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = []\n",
    "for i,M in enumerate(Ms):\n",
    "    X = np.log10(Cs).reshape(-1,1)\n",
    "    y = np.log10(np.array(magnitude_C_M[i,:]))\n",
    "    y = y/y[0]\n",
    "    reg = LinearRegression().fit(X, y)\n",
    "    alphas.append(reg.coef_)\n",
    "alphas = np.array(alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(Ms, alphas)\n",
    "plt.xlabel('Bond dimension M', fontsize=16)\n",
    "plt.ylabel(r'$\\alpha$ coefficient', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'TensorNetwork' from '/home/francesco/UNIPD/Information_Theory/TensorNetworkForML/TensorNetwork/TensorNetwork.py'>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(tn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear dimensions tested: \n",
      " [ 4  8 12 16 20 24 28]\n"
     ]
    }
   ],
   "source": [
    "linear_dims = np.arange(4,29,4)\n",
    "print(\"Linear dimensions tested: \\n\", linear_dims)\n",
    "\n",
    "# keep them fixed\n",
    "n_samples = 1000\n",
    "M = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with 4 x 4 images...\n",
      "Normalizing weights...\n",
      "Scaling factor: 12.80\n",
      "Calibrating weights on dataset...\n",
      "f_max for random input of 16 samples :  1.6712556430879646\n",
      "Rescaling factor for calibration:  1.0326191633351856\n",
      "f_max for random input of 16 samples (after):  1.6712556430879646\n",
      "Testing with 8 x 8 images...\n",
      "Normalizing weights...\n",
      "Scaling factor: 12.80\n",
      "Calibrating weights on dataset...\n",
      "f_max for random input of 16 samples :  1.7318445003579228\n",
      "Rescaling factor for calibration:  1.0086179699993059\n",
      "f_max for random input of 16 samples (after):  1.7318445003579228\n",
      "Testing with 12 x 12 images...\n",
      "Normalizing weights...\n",
      "Scaling factor: 12.80\n",
      "Calibrating weights on dataset...\n",
      "f_max for random input of 16 samples :  1.1647029409294452\n",
      "Rescaling factor for calibration:  1.0010593528583895\n",
      "f_max for random input of 16 samples (after):  1.1647029409294452\n",
      "Testing with 16 x 16 images...\n",
      "Normalizing weights...\n",
      "Scaling factor: 12.80\n",
      "Calibrating weights on dataset...\n",
      "f_max for random input of 16 samples :  0.7054761376532831\n",
      "Rescaling factor for calibration:  0.9986381066119446\n",
      "f_max for random input of 16 samples (after):  0.7054761376532831\n",
      "Testing with 20 x 20 images...\n",
      "Normalizing weights...\n",
      "Scaling factor: 12.80\n",
      "Calibrating weights on dataset...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-b6b4a4ead098>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# independent from the number of samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlinear_dim\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/UNIPD/Information_Theory/TensorNetworkForML/TensorNetwork/TensorNetwork.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, N, M, D, L, normalize, calibration_X)\u001b[0m\n\u001b[1;32m    683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0;31m# compute the order of magnitude of the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m             \u001b[0mf_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'f_max for random input of %d samples : '\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/UNIPD/Information_Theory/TensorNetworkForML/TensorNetwork/TensorNetwork.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    743\u001b[0m         \u001b[0;31m#A_TX = np.vectorize(contract)(TX, A, contracted='d'+str(i))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 745\u001b[0;31m         \u001b[0mA_TX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcontract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontracted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'd'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    746\u001b[0m         \u001b[0mcum_contraction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m         \u001b[0mcum_contraction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA_TX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/UNIPD/Information_Theory/TensorNetworkForML/TensorNetwork/TensorNetwork.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    743\u001b[0m         \u001b[0;31m#A_TX = np.vectorize(contract)(TX, A, contracted='d'+str(i))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 745\u001b[0;31m         \u001b[0mA_TX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcontract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontracted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'd'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    746\u001b[0m         \u001b[0mcum_contraction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m         \u001b[0mcum_contraction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA_TX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/UNIPD/Information_Theory/TensorNetworkForML/TensorNetwork/TensorNetwork.py\u001b[0m in \u001b[0;36mcontract\u001b[0;34m(T1, T2, contracted_axis1, contracted_axis2, common_axis1, common_axis2, contracted, common)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[0;31m# call _contract_ function for actual contraction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_contract_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontracted_axis1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontracted_axis2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommon_axis1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommon_axis2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/UNIPD/Information_Theory/TensorNetworkForML/TensorNetwork/TensorNetwork.py\u001b[0m in \u001b[0;36m_contract_\u001b[0;34m(T1, T2, contracted_axis1, contracted_axis2, common_axis1, common_axis2)\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontracted_axis1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0;31m# if len(contracted_axis1) == 0 just to tensor product\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0mT3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0mT3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mT3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mT3_axes_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     36\u001b[0m def _sum(a, axis=None, dtype=None, out=None, keepdims=False,\n\u001b[1;32m     37\u001b[0m          initial=_NoValue, where=True):\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m def _prod(a, axis=None, dtype=None, out=None, keepdims=False,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "magnitude_linear_dims = []\n",
    "for linear_dim in linear_dims:\n",
    "    print(\"Testing with %d x %d images...\"%(linear_dim,linear_dim))\n",
    "    (data, label) = gen.create_dataset(n_samples, sigma=0.7, linear_dim = linear_dim)\n",
    "    batch_size = {'train_batch_size':16, 'val_batch_size':128, 'test_batch_size':128}\n",
    "    train_loader, val_loader, test_loader = prepare_dataset(data, label, 0.8, 0.2, **batch_size)\n",
    "    \n",
    "    # independent from the number of samples\n",
    "    net = tn.Network(N=linear_dim**2, M=M, L=2, normalize=True)\n",
    "    \n",
    "    batch = next(iter(train_loader))\n",
    "    X = np.array([batch[i][0] for i in range(len(batch))])\n",
    "    f = net.forward(X)\n",
    "    f_max = np.abs(f.elem).max()\n",
    "    magnitude_linear_dims.append(f_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = np.random.random(10000)\n",
    "x = np.cos(np.pi/2*u)\n",
    "x.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "magnitude_linear_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ns = linear_dims**2\n",
    "y = np.log10(magnitude_linear_dims)\n",
    "X = Ns.reshape(-1,1)\n",
    "reg = LinearRegression().fit(X, y)\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(Ns, y, label = 'data')\n",
    "plt.plot(Ns, reg.predict(X), label = 'slope = %.2f'%reg.coef_)\n",
    "plt.ylabel(r'$log_{10}(f_{max})$', fontsize = 16)\n",
    "plt.xlabel('Number of pixels N', fontsize = 16)\n",
    "plt.legend(fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient clipping\n",
    "**Idea**: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.measure\n",
    "\n",
    "def pooling(X):\n",
    "    X = skimage.measure.block_reduce(X, (1,2,2), np.max)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNIST_data = gen.get_MNIST_dataset(data_root_dir = './datasets', download=False)\n",
    "train_data, train_labels, test_data, test_labels = MNIST_data\n",
    "data = np.concatenate((train_data,test_data))\n",
    "data = pooling(data)\n",
    "labels = np.concatenate((train_labels,test_labels))\n",
    "batch_size = {'train_batch_size':32, 'val_batch_size':128, 'test_batch_size':128}\n",
    "train_loader, val_loader, test_loader = prepare_dataset(data, labels, 6/7, 0.2, **batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask1 = (labels == 0) \n",
    "mask2 = (labels == 1)\n",
    "mask = mask1 + mask2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels01 = labels[mask]\n",
    "data01 = data[mask]\n",
    "\n",
    "batch_size = {'train_batch_size':2048, 'val_batch_size':128, 'test_batch_size':128}\n",
    "train_loader, val_loader, test_loader = prepare_dataset(data01, labels01, 1, 0.2, **batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'TensorNetwork' from '/home/francesco/UNIPD/Information_Theory/TensorNetworkForML/TensorNetwork/TensorNetwork.py'>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(tn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_batch = next(iter(train_loader))\n",
    "x_calibration = np.array([calibration_batch[i][0] for i in range(len(calibration_batch))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing weights...\n",
      "Scaling factor: 12.80\n",
      "Calibrating weights on dataset...\n",
      "f_max for random input of 2048 samples :  2.6746259388568886e-21\n",
      "Rescaling factor for calibration:  0.7853026380819934\n",
      "f_max for random input of 2048 samples (after):  0.9999999999999867\n"
     ]
    }
   ],
   "source": [
    "net = tn.Network(N=196, M=20, L=2, normalize=True, calibration_X=x_calibration) #, sigma=0.23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58d5460e716e487e8139c0dc3e37b539",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch loop', max=10, style=ProgressStyle(description_width='iâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DeltaB:  0.20378351715746215\n",
      "B (after update): \t 50.66742370823836\n",
      "f(B):  44.28489817396586\n",
      "batch_acc:  0.49560546875\n",
      "batch_acc_opt:  0.50830078125\n",
      "Epoch 0 - train accuracy : 0.4956 - completed : 20.00 % \n",
      "DeltaB:  0.6884522554123007\n",
      "B (after update): \t 68.73254727456438\n",
      "f(B):  101.80759042562498\n",
      "batch_acc:  0.48828125\n",
      "batch_acc_opt:  0.51123046875\n",
      "Epoch 0 - train accuracy : 0.4883 - completed : 40.00 % \n",
      "DeltaB:  0.6978781813176849\n",
      "B (after update): \t 69.84463983187915\n",
      "f(B):  368.5763001885889\n",
      "batch_acc:  0.4755859375\n",
      "batch_acc_opt:  0.57080078125\n",
      "Epoch 0 - train accuracy : 0.4756 - completed : 60.00 % \n",
      "DeltaB:  1.1549746175286073\n",
      "B (after update): \t 115.85368591714214\n",
      "f(B):  145.5202421879007\n",
      "batch_acc:  0.5146484375\n",
      "batch_acc_opt:  0.52978515625\n",
      "Epoch 0 - train accuracy : 0.5146 - completed : 80.00 % \n",
      "DeltaB:  0.9224421681904273\n",
      "B (after update): \t 92.76713989009814\n",
      "f(B):  607.4265181056594\n",
      "batch_acc:  0.48828125\n",
      "batch_acc_opt:  0.61962890625\n",
      "Epoch 0 - train accuracy : 0.4925 - val accuracy: 0.5085 \n",
      "\n",
      "DeltaB:  1.5068064447522147\n",
      "B (after update): \t 150.46835412466197\n",
      "f(B):  338.18209456674924\n",
      "batch_acc:  0.54296875\n",
      "batch_acc_opt:  0.5146484375\n",
      "Epoch 1 - train accuracy : 0.5430 - completed : 20.00 % \n",
      "DeltaB:  1.159984347196829\n",
      "B (after update): \t 142.7410485559293\n",
      "f(B):  365.61489827417404\n",
      "batch_acc:  0.5029296875\n",
      "batch_acc_opt:  0.57080078125\n",
      "Epoch 1 - train accuracy : 0.5029 - completed : 40.00 % \n",
      "DeltaB:  1.5934494020838945\n",
      "B (after update): \t 159.29109480441372\n",
      "f(B):  229.1259200084117\n",
      "batch_acc:  0.5146484375\n",
      "batch_acc_opt:  0.50927734375\n",
      "Epoch 1 - train accuracy : 0.5146 - completed : 60.00 % \n",
      "DeltaB:  1.3251785177269242\n",
      "B (after update): \t 132.73217592301648\n",
      "f(B):  199.8259268993284\n",
      "batch_acc:  0.49853515625\n",
      "batch_acc_opt:  0.52392578125\n",
      "Epoch 1 - train accuracy : 0.4985 - completed : 80.00 % \n",
      "DeltaB:  1.856489035040012\n",
      "B (after update): \t 185.48228351156564\n",
      "f(B):  378.26507968889916\n",
      "batch_acc:  0.486328125\n",
      "batch_acc_opt:  0.50146484375\n",
      "Epoch 1 - train accuracy : 0.5091 - val accuracy: 0.5105 \n",
      "\n",
      "DeltaB:  1.5655892193670202\n",
      "B (after update): \t 156.05610867305518\n",
      "f(B):  170.74500102111818\n",
      "batch_acc:  0.51025390625\n",
      "batch_acc_opt:  0.5244140625\n",
      "Epoch 2 - train accuracy : 0.5103 - completed : 20.00 % \n",
      "DeltaB:  2.070709192418819\n",
      "B (after update): \t 207.36009346218705\n",
      "f(B):  3940.877853170542\n",
      "batch_acc:  0.52001953125\n",
      "batch_acc_opt:  0.505859375\n",
      "Epoch 2 - train accuracy : 0.5200 - completed : 40.00 % \n",
      "DeltaB:  1.7553735195095541\n",
      "B (after update): \t 175.88032997003222\n",
      "f(B):  1045.7389150200017\n",
      "batch_acc:  0.490234375\n",
      "batch_acc_opt:  0.51171875\n",
      "Epoch 2 - train accuracy : 0.4902 - completed : 60.00 % \n",
      "DeltaB:  1.9855310976354803\n",
      "B (after update): \t 198.61998251792104\n",
      "f(B):  101811.66520292783\n",
      "batch_acc:  0.5048828125\n",
      "batch_acc_opt:  0.4951171875\n",
      "Epoch 2 - train accuracy : 0.5049 - completed : 80.00 % \n",
      "DeltaB:  2.0001805704183138\n",
      "B (after update): \t 199.90964276299835\n",
      "f(B):  2241.5888666992546\n",
      "batch_acc:  0.51953125\n",
      "batch_acc_opt:  0.52490234375\n",
      "Epoch 2 - train accuracy : 0.5090 - val accuracy: 0.5146 \n",
      "\n",
      "DeltaB:  2.209227742863533\n",
      "B (after update): \t 220.9733483494324\n",
      "f(B):  2030.3106125964305\n",
      "batch_acc:  0.4951171875\n",
      "batch_acc_opt:  0.50390625\n",
      "Epoch 3 - train accuracy : 0.4951 - completed : 20.00 % \n",
      "DeltaB:  2.016177186889873\n",
      "B (after update): \t 201.16828695729498\n",
      "f(B):  1436.3788966201814\n",
      "batch_acc:  0.4873046875\n",
      "batch_acc_opt:  0.48681640625\n",
      "Epoch 3 - train accuracy : 0.4873 - completed : 40.00 % \n",
      "DeltaB:  2.2609845266243576\n",
      "B (after update): \t 226.22485602420915\n",
      "f(B):  283.16448783250854\n",
      "batch_acc:  0.52099609375\n",
      "batch_acc_opt:  0.48583984375\n",
      "Epoch 3 - train accuracy : 0.5210 - completed : 60.00 % \n",
      "DeltaB:  2.1148956777302637\n",
      "B (after update): \t 211.28382224001604\n",
      "f(B):  218.87100800118174\n",
      "batch_acc:  0.4990234375\n",
      "batch_acc_opt:  0.5048828125\n",
      "Epoch 3 - train accuracy : 0.4990 - completed : 80.00 % \n",
      "DeltaB:  2.310362751787004\n",
      "B (after update): \t 231.151228397514\n",
      "f(B):  3232.9895107553057\n",
      "batch_acc:  0.5078125\n",
      "batch_acc_opt:  0.5029296875\n",
      "Epoch 3 - train accuracy : 0.5021 - val accuracy: 0.4959 \n",
      "\n",
      "DeltaB:  2.3541293281509508\n",
      "B (after update): \t 235.29957704836406\n",
      "f(B):  835.404483553337\n",
      "batch_acc:  0.47314453125\n",
      "batch_acc_opt:  0.51220703125\n",
      "Epoch 4 - train accuracy : 0.4731 - completed : 20.00 % \n",
      "DeltaB:  2.415645404458231\n",
      "B (after update): \t 241.56334048640701\n",
      "f(B):  198.53474169346805\n",
      "batch_acc:  0.50927734375\n",
      "batch_acc_opt:  0.4931640625\n",
      "Epoch 4 - train accuracy : 0.5093 - completed : 40.00 % \n",
      "DeltaB:  2.3965965078163567\n",
      "B (after update): \t 239.71263244610134\n",
      "f(B):  208.44010174911378\n",
      "batch_acc:  0.5087890625\n",
      "batch_acc_opt:  0.5068359375\n",
      "Epoch 4 - train accuracy : 0.5088 - completed : 60.00 % \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-146-b7e63445f58e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/UNIPD/Information_Theory/TensorNetworkForML/TensorNetwork/TensorNetwork.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_loader, val_loader, lr, n_epochs, early_stopping, print_freq)\u001b[0m\n\u001b[1;32m    807\u001b[0m                     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mr_sweep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml_pos\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 809\u001b[0;31m                     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml_sweep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    810\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nl index is neither at the end or at the beginning of the net\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/UNIPD/Information_Theory/TensorNetworkForML/TensorNetwork/TensorNetwork.py\u001b[0m in \u001b[0;36ml_sweep\u001b[0;34m(self, X, y, f, lr)\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    990\u001b[0m             \u001b[0;31m#print(\"\\nleft sweep step \",self.N-1-i)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 991\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml_sweep_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    992\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/UNIPD/Information_Theory/TensorNetworkForML/TensorNetwork/TensorNetwork.py\u001b[0m in \u001b[0;36ml_sweep_step\u001b[0;34m(self, f, y, lr, batch_size)\u001b[0m\n\u001b[1;32m   1264\u001b[0m             \u001b[0;31m# both right and left terms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml_cum_contraction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'right'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'left'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# ok\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1266\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mr_cum_contraction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'right'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'left'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# ok\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# l=1 case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/UNIPD/Information_Theory/TensorNetworkForML/TensorNetwork/TensorNetwork.py\u001b[0m in \u001b[0;36mcontract\u001b[0;34m(T1, T2, contracted_axis1, contracted_axis2, common_axis1, common_axis2, contracted, common)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[0;31m# call _contract_ function for actual contraction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_contract_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontracted_axis1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontracted_axis2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommon_axis1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommon_axis2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/UNIPD/Information_Theory/TensorNetworkForML/TensorNetwork/TensorNetwork.py\u001b[0m in \u001b[0;36m_contract_\u001b[0;34m(T1, T2, contracted_axis1, contracted_axis2, common_axis1, common_axis2)\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontracted_axis1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0;31m# if len(contracted_axis1) == 0 just to tensor product\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0mT3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0mT3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mT3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mT3_axes_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     36\u001b[0m def _sum(a, axis=None, dtype=None, out=None, keepdims=False,\n\u001b[1;32m     37\u001b[0m          initial=_NoValue, where=True):\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m def _prod(a, axis=None, dtype=None, out=None, keepdims=False,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_acc, val_acc = net.train(train_loader, val_loader, lr = 0.01, n_epochs = 10, print_freq=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 5\n",
    "plt.imshow(data01[n])\n",
    "plt.show()\n",
    "labels01[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
